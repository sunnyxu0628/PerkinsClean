{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e340587",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Perkins Core Indicators - Clean & Merge Files\n",
    "Developed by Qingai \"Sunny\" Xu, CTE Research Expert, San Diego Community College District\n",
    "\n",
    "This notebook provides a step-by-step guide to cleaning and merging data files for the Perkins Core Indicators Project. The cleaned data can then be uploaded to a Power BI dashboard for visualization and analysis.\n",
    "\n",
    "Before running this notebook, make sure you have downloaded all the required files.  \n",
    "To automate the data collection process, please visit [https://github.com/sunnyxu0628/PerkinsReportScraper](https://github.com/sunnyxu0628/PerkinsReportScraper), where I have developed code to streamline the downloading process.  \n",
    "\n",
    "If you prefer to manually download the files, please use this notebook to clean the data:  \n",
    "[**CleanPerkins-ManualDownloaded.ipynb**](CleanPerkins-ManualDownloaded.ipynb)\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Setup and Configuration](#setup)  \n",
    "2. [Data Transformation and Combination](#data-transformation)  \n",
    "3. [Data Cleaning](#data-cleaning)  \n",
    "4. [Data Export](#data-export)  \n",
    "5. [Optional: Data Reshaping (Long to Wide Format)](#reshaping)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5a5b34-13cd-4908-8b20-a9a65d30e5c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "<a id='setup'></a>\n",
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f55e6af-e7aa-409a-a1a1-07c152a04ca0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "### Install Required Packages\n",
    "\n",
    "Uncomment and run the cell below if you haven't installed the required packages. This should be done only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37c71d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas numpy os \n",
    "# %pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f4b579",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "490c7f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "# Set pandas to display all rows\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49a633d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Configuration\n",
    "\n",
    "Define your working environment and specify the number of colleges you're dealing with. This section allows you to easily adjust the notebook based on your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "288db7d4-bcc7-481b-903a-050a86d363a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Base folder path for the Perkins project\n",
    "Perkins_folder_path = Path('G:/Shared/SS/From RPNet/CTE Research/Perkins/Core Indicators/PerkinsReportScraper-main')\n",
    "\n",
    "# Specify the list of colleges and their corresponding data paths\n",
    "# You can add or remove entries from this dictionary based on the colleges you are working with\n",
    "\n",
    "\n",
    "colleges = {\n",
    "    # Format:\n",
    "    # 'Standardized College Name': (Path to Top Code data folder, College name as it appears in the raw files)\n",
    "    # The 'Standardized College Name' will be used in the final output files\n",
    "\n",
    "    'City College': (Perkins_folder_path / 'Data/Top Code/San Diego City College', 'San Diego City College'),\n",
    "    'Mesa College': (Perkins_folder_path / 'Data/Top Code/San Diego Mesa College', 'San Diego Mesa College'),\n",
    "    'Miramar College': (Perkins_folder_path / 'Data/Top Code/San Diego Miramar College Reg Cntr', 'San Diego Miramar College Reg Cntr'),\n",
    "    # Add more colleges here if needed\n",
    "}\n",
    "\n",
    "# Paths to college level and district level Core Indicators Data\n",
    "college_level_path = Perkins_folder_path / 'Data/College/'\n",
    "district_level_path = Perkins_folder_path / 'Data/District/'\n",
    "\n",
    "# Paths to store raw and cleaned data\n",
    "data_raw_path = Perkins_folder_path / 'Data'\n",
    "data_clean_path = Perkins_folder_path / 'Data_Clean'\n",
    "os.makedirs(data_clean_path, exist_ok=True)\n",
    "\n",
    "# Export file name configuration\n",
    "final_top6_export_file_name = 'Perkins_top6_2020_2026'\n",
    "final_college_export_file_name = 'Perkins_college_2020_2026'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed97a46b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "<a id='data-transformation'></a>\n",
    "## 2. Data Transformation and Merging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5518cbd9-a9ec-4d19-a3c6-bfa78d0c89cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Lists of File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c0b9856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store file lists for each college\n",
    "college_files = {}\n",
    "  \n",
    "# Create a dictionary to store file lists for each college\n",
    "college_files = {}\n",
    "\n",
    "for college_name, (path, _) in colleges.items():\n",
    "    college_files[college_name] = [os.path.join(path, i) for i in os.listdir(path) if i.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84166770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined list of all college-level and district-level files\n",
    "college_district_files = [college_level_path / i for i in os.listdir(college_level_path) if i.endswith('.csv')] + \\\n",
    "            [district_level_path / i for i in os.listdir(district_level_path) if i.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946061b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Helper functions: Define Functions for Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4debc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_combine_tables(file_list, name):\n",
    "    \"\"\"\n",
    "    Combine transformed tables and save as a single CSV file.\n",
    "\n",
    "    Args:\n",
    "        file_list (list): List of file paths.\n",
    "        name (str): Name for the output CSV file.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store DataFrames\n",
    "    dataframes = []\n",
    "\n",
    "    # Iterate through each file path in the list\n",
    "    for file_path in file_list:\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Extract 'College' and 'Top Code' from the file name\n",
    "        file_name = os.path.basename(file_path)\n",
    "        college_name = file_name.split('_')[0]  # Extract the college name\n",
    "        top_code = file_name.split('_')[2].replace('.csv', '')  # Extract the Top Code\n",
    "\n",
    "        # Add 'College' and 'Top Code' columns to the DataFrame\n",
    "        df.insert(0, 'College', college_name)  # Add 'College' as the first column\n",
    "        df.insert(1, 'Top Code', top_code)    # Add 'Top Code' as the second column\n",
    "\n",
    "        # Drop rows where 'Negotiated Level - District' is 'District'\n",
    "        df = df[df['Negotiated Level - District'] != 'District']\n",
    "\n",
    "        # Append the cleaned DataFrame to the list\n",
    "        dataframes.append(df)\n",
    "\n",
    "    # Combine all DataFrames into a single DataFrame\n",
    "    output = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Save the combined DataFrame to a CSV file\n",
    "    output.to_csv(os.path.join(data_clean_path, name + '_combined_raw_top6.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9a32b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_college_district_tables(file_list):\n",
    "    \"\"\"\n",
    "    Combine transformed tables into a single DataFrame.\n",
    "\n",
    "    Args:\n",
    "        file_list (list): List of file paths.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame with added 'College/District' column.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store DataFrames\n",
    "    dataframes = []\n",
    "\n",
    "    # Iterate through each file path in the list\n",
    "    for file_path in file_list:\n",
    "\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Extract 'College' from the file name\n",
    "        file_name = os.path.basename(file_path)\n",
    "        college_name = file_name.split('_')[0]  # Extract the college name\n",
    "\n",
    "        # Adjust 'College' name: Keep \"San Diego District\" as is, otherwise drop \"San Diego\"\n",
    "        if college_name == \"San Diego District\":\n",
    "            pass\n",
    "        else:\n",
    "            college_name = college_name.replace(\"San Diego \", \"\")\n",
    "\n",
    "        # Add 'College/District' column to the DataFrame\n",
    "        df.insert(0, 'College/District', college_name)\n",
    "\n",
    "        # Drop rows where 'Negotiated Level - District' is invalid\n",
    "        df = df[df['Negotiated Level - District'] != 'Page 1 of 1']\n",
    "\n",
    "        # Append the cleaned DataFrame to the list\n",
    "        dataframes.append(df)\n",
    "    output = pd.concat(dataframes, ignore_index=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6289c211",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Apply Transformation and Save Combined Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0df6121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and save the combined tables for each college\n",
    "for college_name, files in college_files.items():\n",
    "    save_combine_tables(files, college_name.replace(' ', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22b999c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "college_district_df = combine_college_district_tables(college_district_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcc6414",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "<a id='data-cleaning'></a>\n",
    "## 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b360465",
   "metadata": {},
   "source": [
    "### Top6 Level Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6957d0fe-bd1d-4d8a-b234-675c51a73c7f",
   "metadata": {},
   "source": [
    "#### Load Combined Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5122c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the combined CSV files into DataFrames\n",
    "college_dfs = {}\n",
    "\n",
    "for college_name in colleges.keys():\n",
    "    df = pd.read_csv(os.path.join(data_clean_path, college_name.replace(' ', '') + '_combined_raw_top6.csv'), dtype=str)\n",
    "    college_dfs[college_name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336de880",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Merge into a Single File & Rebale Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a715c65e",
   "metadata": {},
   "source": [
    "##### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "edda17ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define if the core indicator meets the Negotiated Goal level\n",
    "def calculate_90goal_flag(row):\n",
    "    if row['Percent Above or Below 90% Negotiated Level'] == 'N/A':\n",
    "        return 'N/A'\n",
    "    elif row['Percent Above or Below 90% Negotiated Level'] == 'N/R':\n",
    "        return 'N/R'\n",
    "    elif float(row['Percent Above or Below 90% Negotiated Level']) >= 0 :\n",
    "        return 'MET'\n",
    "    elif float(row['Percent Above or Below 90% Negotiated Level']) < 0 :\n",
    "        return 'NOT MET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fad2a217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define if the core indicator meets the 'District Negotiated Goal'\n",
    "def calculate_district_goal(row):\n",
    "    if row['Percent Above or Below Negotiated Level'] == 'N/A':\n",
    "        return 'N/A'\n",
    "    elif row['Percent Above or Below Negotiated Level'] == 'N/R':\n",
    "        return 'N/R'\n",
    "    elif pd.isna(row['College Performance Number']):\n",
    "        return row['College Performance']\n",
    "    elif float(row['Percent Above or Below Negotiated Level']) >= 0 :\n",
    "        return 'MET'\n",
    "    elif float(row['Percent Above or Below Negotiated Level']) < 0 :\n",
    "        return 'NOT MET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "126e5db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataframe(df):\n",
    "    \"\"\"\n",
    "    Transform a DataFrame by cleaning columns, and adding calculated fields.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame to transform.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The transformed DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split 'Core Indicator' into 'Core Indicator' and 'Cohort Year'\n",
    "    df[['Core Indicator', 'Cohort Year']] = df['CI Number'].str.split(\" - Cohort Yr: \", expand=True)\n",
    "    df['Core Indicator'] = df['Core Indicator'].str.strip()\n",
    "    df['Cohort Year'] = df['Cohort Year'].str.strip()\n",
    "\n",
    "    # Fill missing values\n",
    "    df['Percent Above or Below Negotiated Level'] = df['Percent Above or Below Negotiated Level'].fillna('N/A')\n",
    "    df['Percent Above or Below 90% Negotiated Level'] = df['Percent Above or Below 90% Negotiated Level'].fillna('N/A')\n",
    "\n",
    "    # Convert 'College Performance' to numeric\n",
    "    df['College Performance Number'] = pd.to_numeric(df['College Performance'], errors='coerce')\n",
    "\n",
    "    # Add calculated columns\n",
    "    df['90% Negotiated Goal Indicator'] = df.apply(calculate_90goal_flag, axis=1)\n",
    "    df['District Negotiated Goal Indicator'] = df.apply(calculate_district_goal, axis=1)\n",
    "    df['Negotiated level - 90% District'] = (\n",
    "        pd.to_numeric(df['Negotiated Level - District'], errors='coerce') * 0.9\n",
    "    ).round(2)\n",
    "\n",
    "    # Create additional columns\n",
    "    df['Core Indicators'] = df['Core Indicator'].astype(str) + ' : ' + df['CI Info'].astype(str)\n",
    "    df['College Performance Decimal'] = df['College Performance Number'] / 100\n",
    "    df['Negotiated level - 90% District Decimal'] = pd.to_numeric(df['Negotiated level - 90% District'], errors='coerce') / 100\n",
    "    df['Negotiated Level - State Decimal'] = pd.to_numeric(df['Negotiated Level - State'], errors='coerce') / 100\n",
    "    df['Negotiated Level - District Decimal'] = pd.to_numeric(df['Negotiated Level - District'], errors='coerce') / 100\n",
    "    df['Percent Above or Below Negotiated Level (%)'] = pd.to_numeric(\n",
    "        df['Percent Above or Below Negotiated Level'], errors='coerce'\n",
    "    )\n",
    "    df['Percent Above or Below 90% Negotiated Level (%)'] = pd.to_numeric(\n",
    "        df['Percent Above or Below 90% Negotiated Level'], errors='coerce'\n",
    "    )\n",
    "\n",
    "    # Calculate fiscal year\n",
    "    def calculate_fiscal_year(cohort_year):\n",
    "        # Extract the start year and calculate fiscal year\n",
    "        start_year = int(cohort_year.split('-')[0]) + 3\n",
    "        end_year = start_year + 1\n",
    "        return f\"{start_year} - {end_year}\"\n",
    "\n",
    "    df['Fiscal Year'] = df['Cohort Year'].apply(calculate_fiscal_year)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8befd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all DataFrames into a single DataFrame\n",
    "all_df = pd.concat(college_dfs.values(), ignore_index=True)\n",
    "\n",
    "#To ensure consistency, we'll standardize the college names in the 'College' column based on the configuration.\n",
    "\n",
    "# Create a replacement dictionary from the colleges configuration\n",
    "replacement_dict = {raw_name: standard_name for standard_name, (_, raw_name) in colleges.items()}\n",
    "\n",
    "# Replace values in 'College' column to standardize names\n",
    "all_df['College'] = all_df['College'].replace(replacement_dict)\n",
    "\n",
    "### Clean Data Columns\n",
    "# Clean 'Top Code' column\n",
    "all_df['Top Code'] = all_df['Top Code'].str.replace('   ', '-')\n",
    "\n",
    "all_df = transform_dataframe(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "120eb6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "college_district_df = transform_dataframe(college_district_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bff9bae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "<a id='data-export'></a>\n",
    "## 6. Data Export\n",
    "\n",
    "### Export Cleaned Data for Each College"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3fe7e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cleaned data for each college\n",
    "for college_name in colleges.keys():\n",
    "    college_df = all_df[all_df['College'] == college_name]\n",
    "    college_df.to_csv(os.path.join(data_clean_path, college_name.replace(' ', '') + 'top6_clean.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbd9dfa",
   "metadata": {},
   "source": [
    "### Save Combined Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "258dcfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_csv(os.path.join(data_clean_path, final_top6_export_file_name + '.csv'), index=False)\n",
    "college_district_df.to_csv(os.path.join(data_clean_path, final_college_export_file_name + '.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
